<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Batch run example code &mdash; How to search for hyper parameters  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sphinx_lesson.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sphinx_rtd_theme_ext_color_contrast.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/overrides.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/minipres.js"></script>
        <script>let toggleHintShow = 'Click to show';</script>
        <script>let toggleHintHide = 'Click to hide';</script>
        <script>let toggleOpenOnPrint = 'true';</script>
        <script src="../_static/togglebutton.js"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex/" />
    <link rel="search" title="Search" href="../search/" />
    <link rel="prev" title="Hyper Parameter Optimization with Optuna" href="../notebooks/hyper_parameter_optimization/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../" class="icon icon-home"> How to search for hyper parameters
            <img src="../_static/ENCCS.jpg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Hyper Parameter Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../hp_introduction/">Hyper Parameter optimization for neural networks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notebook</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/hyper_parameter_optimization/">Hyper Parameter Optimization with Optuna</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Example with cross validation</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Batch run example code</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#installation">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#optimizing-hyper-parameters">Optimizing hyper parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="#manual-hyper-parameter-optimization">Manual hyper parameter Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hyper-parameter-optimization-with-optuna">Hyper Parameter Optimization with Optuna</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../">How to search for hyper parameters</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Batch run example code</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/ENCCS/hp_optimization/blob/main/content/cross_validation_example.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="batch-run-example-code">
<h1>Batch run example code<a class="headerlink" href="#batch-run-example-code" title="Permalink to this heading"></a></h1>
<p>Here will go through an example where we change some code to use optuna.
You can find the code <a class="reference download internal" download="" href="../_downloads/585567800fd203c92c490010ddef3c85/code_archive.zip"><code class="xref download docutils literal notranslate"><span class="pre">here</span></code></a>.</p>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this heading"></a></h2>
<p>The code relies on anaconda. Create an environment by running</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ conda env create -f environment.yml
</pre></div>
</div>
<p>Once this is done, activate the envioronment by running</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ conda activate hpo_workshop
</pre></div>
</div>
<p>Now we need to make the code in the archive available. After extracting the files, go to the directory you extracted them to and run</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ pip install -e .
</pre></div>
</div>
<p>This installs the partorch package into the active anaconda environment and makes it globally available in the environment.</p>
</section>
<section id="optimizing-hyper-parameters">
<h2>Optimizing hyper parameters<a class="headerlink" href="#optimizing-hyper-parameters" title="Permalink to this heading"></a></h2>
<p>The example implements a simple Long Short-Term Memory (LSTM) network on a
binary sequence prediction dataset. The sequences are molecules encoded in
the SMILES format and the prediction target is whether they risk penetrating
the Blood Brain Barrier or not.</p>
<p>The network is defined in the file <code class="code docutils literal notranslate"><span class="pre">hpo_workshop/rnn.py</span></code> and implemented pytorch, in this example we’re mainly interested in the initialization of the network:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RNNPredictor</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="hll">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span class="hll">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span class="hll">        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
</span><span class="hll">        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
</span><span class="hll">        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">get_num_embeddings</span><span class="p">(),</span>
</span><span class="hll">                                    <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
</span><span class="hll">                                    <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span class="hll">        <span class="bp">self</span><span class="o">.</span><span class="n">recurrent_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
</span><span class="hll">                                        <span class="n">hidden_size</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
</span><span class="hll">                                        <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
</span><span class="hll">                                        <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidirectional</span><span class="p">,</span>
</span><span class="hll">                                        <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
</span><span class="hll">                                        <span class="p">)</span>
</span><span class="hll">        <span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">=</span> <span class="mi">1</span>
</span><span class="hll">        <span class="k">if</span> <span class="n">bidirectional</span><span class="p">:</span>
</span><span class="hll">            <span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">=</span> <span class="mi">2</span>
</span><span class="hll">        <span class="bp">self</span><span class="o">.</span><span class="n">output_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span><span class="o">*</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span><span class="hll">        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span class="hll">        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>
</span><span class="hll">        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_batch</span><span class="p">,</span> <span class="n">lengths</span><span class="p">):</span>
        <span class="n">embedded_sequences</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">sequence_batch</span><span class="p">)</span>
        <span class="n">packed_sequence</span> <span class="o">=</span> <span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">embedded_sequences</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">enforce_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">h_n</span><span class="p">,</span> <span class="n">c_n</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recurrent_layers</span><span class="p">(</span><span class="n">packed_sequence</span><span class="p">)</span>
        <span class="n">final_state</span> <span class="o">=</span> <span class="n">h_n</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">final_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">final_state</span><span class="p">,</span> <span class="n">h_n</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layers</span><span class="p">(</span><span class="n">final_state</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>

    <span class="k">def</span> <span class="nf">loss_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="n">sequence_batch</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">logit_prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">sequence_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">lengths</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">logit_prediction</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">train_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_on_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">eval_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_on_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">eval_and_predict_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">sequence_batch</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">logit_prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">sequence_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">lengths</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">logit_prediction</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
            <span class="n">prob_predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logit_prediction</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">prob_predictions</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
<p>As you can see, we’re taking the hyper parameters of the network as keyword arguments to
the <code class="code docutils literal notranslate"><span class="pre">__init__</span></code> method. Our goal is to find good settings for these hyper parameters.</p>
</section>
<section id="manual-hyper-parameter-optimization">
<h2>Manual hyper parameter Optimization<a class="headerlink" href="#manual-hyper-parameter-optimization" title="Permalink to this heading"></a></h2>
<p>First we start with the basic “Grad Student Descent” example in <code class="code docutils literal notranslate"><span class="pre">scripts/basic_neural_network.py</span></code>. The important part is given in the training loop:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
<span class="k">for</span> <span class="n">visible_index</span><span class="p">,</span> <span class="n">heldout_indices</span> <span class="ow">in</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">tb_writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="s1">&#39;basic_runs&#39;</span><span class="p">)</span>

    <span class="n">visible_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">visible_index</span><span class="p">]</span>
    <span class="n">train_indices</span><span class="p">,</span> <span class="n">dev_indices</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">visible_index</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">visible_labels</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>

    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">smiles_list</span><span class="o">=</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>  <span class="n">indices</span><span class="o">=</span><span class="n">train_indices</span><span class="p">,</span>
                                      <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dev_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">smiles_list</span><span class="o">=</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>  <span class="n">indices</span><span class="o">=</span><span class="n">dev_indices</span><span class="p">,</span>
                                    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
    <span class="n">heldout_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">smiles_list</span><span class="o">=</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>  <span class="n">indices</span><span class="o">=</span><span class="n">heldout_indices</span><span class="p">,</span>
                                        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>

    <span class="n">model_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="n">model_hparams</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                         <span class="n">d_model</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                         <span class="n">num_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                         <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                         <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                         <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>

    <span class="n">heldout_roc_auc</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">dev_dataloader</span><span class="o">=</span><span class="n">dev_dataloader</span><span class="p">,</span> <span class="n">test_dataloader</span><span class="o">=</span><span class="n">heldout_dataloader</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="n">tb_writer</span><span class="p">,</span>
                            <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span> <span class="n">model_class</span><span class="o">=</span><span class="n">RNNPredictor</span><span class="p">,</span> <span class="n">model_args</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(),</span> <span class="n">model_kwargs</span><span class="o">=</span><span class="n">model_kwargs</span><span class="p">,</span> <span class="n">model_hparams</span><span class="o">=</span><span class="n">model_hparams</span><span class="p">)</span>

    <span class="n">tb_writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>Here we are manually setting hyper parameters and then training our models with these. Using tensordboard we can
essentially track how good they are. These runs will be stored in <code class="code docutils literal notranslate"><span class="pre">basic_runs</span></code> so you need to run tensorboard like:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ tensorboard --logdir<span class="o">=</span>basic_runs
</pre></div>
</div>
<p>Try running the experiment a couple of times while changing hyper parameters and see if you can get better results.</p>
</section>
<section id="hyper-parameter-optimization-with-optuna">
<h2>Hyper Parameter Optimization with Optuna<a class="headerlink" href="#hyper-parameter-optimization-with-optuna" title="Permalink to this heading"></a></h2>
<p>We’ll now take a look at how we can easily extend the above example using Optuna. We will replace the work we did with
manually setting hyper parameters with a loop which automatically searches the hyper parameter space. We need to import optuna
and create a new study object for our hyper parameter optimization. We will perform a separate study for each fold in our cross validation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="kn">import</span> <span class="nn">optuna</span>
</span>
<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
<span class="k">for</span> <span class="n">visible_index</span><span class="p">,</span> <span class="n">heldout_indices</span> <span class="ow">in</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">tb_writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="s1">&#39;basic_runs&#39;</span><span class="p">)</span>

    <span class="n">visible_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">visible_index</span><span class="p">]</span>
    <span class="n">train_indices</span><span class="p">,</span> <span class="n">dev_indices</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">visible_index</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">visible_labels</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>

    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">smiles_list</span><span class="o">=</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>  <span class="n">indices</span><span class="o">=</span><span class="n">train_indices</span><span class="p">,</span>
                                      <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dev_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">smiles_list</span><span class="o">=</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>  <span class="n">indices</span><span class="o">=</span><span class="n">dev_indices</span><span class="p">,</span>
                                    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
    <span class="n">heldout_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">smiles_list</span><span class="o">=</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>  <span class="n">indices</span><span class="o">=</span><span class="n">heldout_indices</span><span class="p">,</span>
                                        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>

    <span class="n">model_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="n">model_hparams</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                         <span class="n">d_model</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                         <span class="n">num_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                         <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                         <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                         <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>

    <span class="n">heldout_roc_auc</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">dev_dataloader</span><span class="o">=</span><span class="n">dev_dataloader</span><span class="p">,</span> <span class="n">test_dataloader</span><span class="o">=</span><span class="n">heldout_dataloader</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="n">tb_writer</span><span class="p">,</span>
                            <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span> <span class="n">model_class</span><span class="o">=</span><span class="n">RNNPredictor</span><span class="p">,</span> <span class="n">model_args</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(),</span> <span class="n">model_kwargs</span><span class="o">=</span><span class="n">model_kwargs</span><span class="p">,</span> <span class="n">model_hparams</span><span class="o">=</span><span class="n">model_hparams</span><span class="p">)</span>

<span class="hll">    <span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">&#39;maximize&#39;</span><span class="p">)</span>
</span>
    <span class="n">tb_writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>We’ve now created a new study with the objective of maximizing an objective function. There are two interfaces for running
optunas optimization: the <code class="code docutils literal notranslate"><span class="pre">study.ask()</span></code> / <code class="code docutils literal notranslate"><span class="pre">study.tell()</span></code> interface and the <code class="code docutils literal notranslate"><span class="pre">study.optimize()</span></code> interface.
We looked at how to use <code class="code docutils literal notranslate"><span class="pre">study.ask()</span></code> / <code class="code docutils literal notranslate"><span class="pre">study.tell()</span></code> in the noteboook before and will now use <code class="code docutils literal notranslate"><span class="pre">study.optimize()</span></code>
instead.</p>
<p><code class="code docutils literal notranslate"><span class="pre">study.optimize()</span></code> takes a function to optimize as an input, and we’ll implement it inlined in our optimization loop so it can refer the datasets we’ve set up.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">optuna</span>

<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
<span class="k">for</span> <span class="n">visible_index</span><span class="p">,</span> <span class="n">heldout_indices</span> <span class="ow">in</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">tb_writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="s1">&#39;basic_runs&#39;</span><span class="p">)</span>

    <span class="n">visible_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">visible_index</span><span class="p">]</span>
    <span class="n">train_indices</span><span class="p">,</span> <span class="n">dev_indices</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">visible_index</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">visible_labels</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>

    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">smiles_list</span><span class="o">=</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>  <span class="n">indices</span><span class="o">=</span><span class="n">train_indices</span><span class="p">,</span>
                                      <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dev_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">smiles_list</span><span class="o">=</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>  <span class="n">indices</span><span class="o">=</span><span class="n">dev_indices</span><span class="p">,</span>
                                    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
    <span class="n">heldout_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">smiles_list</span><span class="o">=</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>  <span class="n">indices</span><span class="o">=</span><span class="n">heldout_indices</span><span class="p">,</span>
                                        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>

    <span class="n">model_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="hll">    <span class="k">def</span> <span class="nf">optimization_function</span><span class="p">(</span><span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">Trial</span><span class="p">):</span>
</span><span class="hll">        <span class="n">model_hparams</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
</span><span class="hll">                            <span class="n">d_model</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
</span><span class="hll">                            <span class="n">num_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
</span><span class="hll">                            <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span class="hll">                            <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
</span><span class="hll">                            <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
</span><span class="hll">                            <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
</span><span class="hll">        <span class="n">heldout_roc_auc</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">dev_dataloader</span><span class="o">=</span><span class="n">dev_dataloader</span><span class="p">,</span> <span class="n">test_dataloader</span><span class="o">=</span><span class="n">heldout_dataloader</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="n">tb_writer</span><span class="p">,</span>
</span><span class="hll">                            <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span> <span class="n">model_class</span><span class="o">=</span><span class="n">RNNPredictor</span><span class="p">,</span> <span class="n">model_args</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(),</span> <span class="n">model_kwargs</span><span class="o">=</span><span class="n">model_kwargs</span><span class="p">,</span> <span class="n">model_hparams</span><span class="o">=</span><span class="n">model_hparams</span><span class="p">)</span>
</span><span class="hll">        <span class="k">return</span> <span class="n">heldout_roc_auc</span>
</span>
    <span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">&#39;maximize&#39;</span><span class="p">)</span>
<span class="hll">    <span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">optimization_function</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</span>
    <span class="n">tb_writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>We’ve now set up the study infrastructure, but we’re still not actually
performing any search. The <code class="code docutils literal notranslate"><span class="pre">optimization_function</span></code> we defined takes
a <code class="code docutils literal notranslate"><span class="pre">optuna.Trial</span></code> object as its argument, and this is our interface
to the actual hyper parameter search procedure.</p>
<p>We extend our <code class="code docutils literal notranslate"><span class="pre">optimization_function</span></code> so that the values for the hyper
parameters are give by the trial:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">optuna</span>

<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
<span class="k">for</span> <span class="n">visible_index</span><span class="p">,</span> <span class="n">heldout_indices</span> <span class="ow">in</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">tb_writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="s1">&#39;basic_runs&#39;</span><span class="p">)</span>

    <span class="n">visible_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">visible_index</span><span class="p">]</span>
    <span class="n">train_indices</span><span class="p">,</span> <span class="n">dev_indices</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">visible_index</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">visible_labels</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>

    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">smiles_list</span><span class="o">=</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>  <span class="n">indices</span><span class="o">=</span><span class="n">train_indices</span><span class="p">,</span>
                                      <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dev_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">smiles_list</span><span class="o">=</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>  <span class="n">indices</span><span class="o">=</span><span class="n">dev_indices</span><span class="p">,</span>
                                    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
    <span class="n">heldout_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">smiles_list</span><span class="o">=</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>  <span class="n">indices</span><span class="o">=</span><span class="n">heldout_indices</span><span class="p">,</span>
                                        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>

    <span class="n">model_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">optimization_function</span><span class="p">(</span><span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">Trial</span><span class="p">):</span>
<span class="hll">        <span class="n">model_hparams</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="s1">&#39;embedding_dim&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]),</span>
</span><span class="hll">                             <span class="n">d_model</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="s1">&#39;d_model&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">]),</span>
</span><span class="hll">                             <span class="n">num_layers</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">&#39;num_layers&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
</span><span class="hll">                             <span class="n">bidirectional</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="s1">&#39;bidirectional&#39;</span><span class="p">,</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]),</span>
</span><span class="hll">                             <span class="n">dropout</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s1">&#39;dropout&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span><span class="hll">                             <span class="n">learning_rate</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span class="hll">                             <span class="n">weight_decay</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span>
        <span class="n">heldout_roc_auc</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">dev_dataloader</span><span class="o">=</span><span class="n">dev_dataloader</span><span class="p">,</span> <span class="n">test_dataloader</span><span class="o">=</span><span class="n">heldout_dataloader</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="n">tb_writer</span><span class="p">,</span>
                            <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span> <span class="n">model_class</span><span class="o">=</span><span class="n">RNNPredictor</span><span class="p">,</span> <span class="n">model_args</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(),</span> <span class="n">model_kwargs</span><span class="o">=</span><span class="n">model_kwargs</span><span class="p">,</span> <span class="n">model_hparams</span><span class="o">=</span><span class="n">model_hparams</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">heldout_roc_auc</span>

    <span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">&#39;maximize&#39;</span><span class="p">)</span>
    <span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">optimization_function</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

    <span class="n">tb_writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>Here we are using most of optunas variable types. We’re using the <code class="code docutils literal notranslate"><span class="pre">suggest_categorical</span></code>
method to sample from a set of arbitrary python objects. We could have used <code class="code docutils literal notranslate"><span class="pre">suggest_int</span></code>
for the <code class="code docutils literal notranslate"><span class="pre">embedding_dim</span></code> and <code class="code docutils literal notranslate"><span class="pre">d_model</span></code> hyper parameters, but by supplying a logits
we’re able to focus specific orders of magnitude instead.</p>
<p>For the <code class="code docutils literal notranslate"><span class="pre">learning_rate</span></code> and <code class="code docutils literal notranslate"><span class="pre">weight_decay</span></code> parameters, we want to
explore the values geometrically, so we set the attribute <code class="code docutils literal notranslate"><span class="pre">log=True</span></code>. This samples the values
from a log-transformed space instead, so that we for example are roughly as likely to sample values in the range
<span class="math notranslate nohighlight">\([10^{-4},10^{-3}]\)</span> as in the range <span class="math notranslate nohighlight">\([10^{-3},10^{-2}]\)</span>. If we don’t do this, our sampling
will be skewed towards larger values.</p>
<p>We have changed our basic version of the training to automatically search for hyper paramters using Optuna.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../notebooks/hyper_parameter_optimization/" class="btn btn-neutral float-left" title="Hyper Parameter Optimization with Optuna" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, ENCCS Hyper Parameter Optimization Workshop and individual contributors..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>